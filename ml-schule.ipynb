{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Text Daten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43679 Reden wurden geladen\n",
      "\n",
      "****************************\n",
      "Beispiele von Partei cducsu:\n",
      "****************************\n",
      "\n",
      "\n",
      "*******************************\n",
      "Sprecher Julia Bartz:\n",
      "\n",
      "Sehr geehrte Frau Präsidentin! Liebe Kolleginnen und Kollegen! Am 24. September eröffnete unser Bundestagspräsident Norbert Lammert die Ausstellung \"Operation Heimkehr\". Im Paul-Löbe-Haus sind immer noch die Fotoaufnahmen von Soldatinnen und Soldaten zu sehen, die von Auslandseinsätzen zurückgekehrt sind. Hieraus zitiere ich Hauptfeldwebel Holger Roßmeier, der traumatisiert aus Afghanistan zurückkam:\n",
      "\n",
      "Früher war ich jemand, der immer alles hinbekommen hat, einer, auf den man sich hundertprozentig verlassen konnte. Und plötzlich schaffte ich es nicht einmal mehr, morgens aufzustehen. Ich wollte aber nicht als Weichei dastehen. Deshalb habe ich jede Therapie zunächst abgelehnt.\n",
      "\n",
      "Wir alle wissen: Auslandseinsätze können traumatisch sein. Die Erfahrungen, Erlebnisse und Eindrücke haben häufig langfristige Folgen, die teilweise erst später zutage treten. Es sind oft kurze Momente, die sich tief in die Seele einbrennen. Als Entscheider über Auslandseinsätze hat der Deutsche Bundestag eine besondere Verantwortung gegenüber denjenigen Soldatinnen und Soldaten, die mit einer Einsatzschädigung nach Hause zurückkehren.\n",
      "\n",
      "In Afghanistan haben wir schmerzhafte Erfahrungen machen müssen, aus denen wir aber die richtigen Konsequenzen gezogen haben: Posttraumatische Belastungsstörungen wurden als Einsatzschädigung anerkannt, und die medizinische Behandlung wurde ausgebaut. Wir haben aus den Einsatzerfahrungen am Hindukusch gelernt und die Versorgung unserer Soldatinnen und Soldaten entsprechend angepasst:\n",
      "\n",
      "2004 wurden mit dem Einsatzversorgungsgesetz die Versorgungsleistungen für Soldaten im Auslandseinsatz verbessert. Damals wurde auch der Stichtag 1. Dezember 2002 festgeschrieben.\n",
      "\n",
      "Mit dem Einsatz-Weiterverwendungsgesetz von 2007 haben Soldatinnen und Soldaten sowie Zivilbeschäftigte, die während eines Auslandseinsatzes schwer verwundet wurden, ein Anrecht auf Weiterbeschäftigung bekommen.\n",
      "\n",
      "Mit dem Einsatzversorgungs-Verbesserungsgesetz von 2011 haben wir die Versorgung von Einsatzgeschädigten und Hinterbliebenen weiter verbessert. Die Entschädigungsleistung für Betroffene haben wir von 80 000 Euro auf 150 000 Euro fast verdoppelt.\n",
      "\n",
      "*******************************\n",
      "Sprecher Ute Granold:\n",
      "\n",
      "Frau Präsidentin! Liebe Kolleginnen und Kollegen! Lassen Sie mich heute als Mitglied des Ausschusses für Menschenrechte und humanitäre Hilfe den Akzent auf den Bereich der Menschenrechte in der deutschen Außenpolitik setzen. Deutsche Außenpolitik ist neben der Friedenspolitik das Politikfeld für den Einsatz für Menschenrechte. Das haben wir im Koalitionsvertrag ganz klar festgelegt und geregelt. Insofern gibt es sowohl einen Kompass als auch ein Steuern auf ein bestimmtes Ziel hin.\n",
      "\n",
      "Die Bundeskanzlerin hat in der letzten Legislaturperiode die wertegebundene Außenpolitik als Akzent gesetzt. Das wird jetzt kontinuierlich fortgesetzt. Dafür sind wir sehr dankbar. Deutschland genießt diesbezüglich ein großes Ansehen in der Welt.\n",
      "\n",
      "Herr Minister, Sie waren vor zwei Wochen beim Menschenrechtsrat der Vereinten Nationen in Genf und haben dort für Deutschland gesprochen. Sie haben für diese Rede über den Kurs der deutschen Außenpolitik zugunsten der Menschenrechtspolitik großes Lob erfahren. Sie haben viele Gespräche geführt. Eine Delegation aus dem Menschenrechtsausschuss war eine Woche später in Genf und hat davon erfahren. Wir sind sehr dankbar für diese klare Position und die nochmalige Betonung des Auftrags zur Förderung der Menschenrechte. Wir haben für den Einsatz, aber auch für die finanzielle Unterstützung Deutschlands für die Einhaltung und Förderung der Menschenrechte in der Welt Anerkennung erfahren. Dafür sind wir dankbar.\n",
      "\n",
      "****************************\n",
      "Beispiele von Partei fdp:\n",
      "****************************\n",
      "\n",
      "\n",
      "*******************************\n",
      "Sprecher Dr. Rainer Stinner:\n",
      "\n",
      "In diesem Antrag geht es nicht mehr und nicht weniger um die dringend gebotene Verbesserung der Lebensbedingungen im Gaza. Wir hatten heute Morgen wieder mit John Ging beim Frühstück ein interessantes Gespräch, in dem er uns eindrücklich geschildert hat, welche miserablen Bedingungen humanitärer Art im Gazastreifen herrschen. Das Wichtige daran ist erstens die humanitäre Frage, die gelöst werden muss. Die ist aber in vielen Teilen der Welt ähnlich schlimm. Hinzu kommt aber zweitens: Wir sind der festen Überzeugung, dass die Negativsituation im Gazastreifen gegen die Interessen Israels gerichtet ist und dass sie insbesondere die Interessen der Hamas fördert. Denn der Hamas ist es durch die Blockade, die wir erleben, gelungen, eine Tunnel- und Schattenwirtschaft aufzubauen, bei der sehr viel Geld fließt und sehr viele Leute reich werden. Der für die Entwicklung des Gazastreifens dringend notwendige Aufbau einer tragenden Wirtschaft im Gazastreifen wird dadurch aber nicht erreicht.\n",
      "\n",
      "Ich sage sehr deutlich: Nach unserem Dafürhalten erhöht die Verbesserung der Lebenssituation im Gazastreifen gerade auch die Sicherheit Israels. Auch deshalb ist es so wichtig, dass wir hier entsprechend vorankommen.\n",
      "\n",
      "*******************************\n",
      "Sprecher Horst Meierhofer:\n",
      "\n",
      "Frau Höhn, das, was Sie gesagt haben, ist zu einem großen Teil richtig. Eine ganze Menge dieser Punkte haben wir in unserem Entschließungsantrag aufgelistet.\n",
      "\n",
      "Bei den Flussgebietsgemeinschaften dürfen nicht mehr nur einzelne Abschnitte betrachtet werden. Das gilt sowohl für die Elbe als auch für die Donau. Daneben stellt sich die Frage, wie man es schafft, dass weniger Wasser in die großen Hochwassergebiete fließt, sodass die Schutzmauern nicht mehr so hoch gebaut werden müssen. Das ist sicher auch ein wichtiger Punkt. Hier müssen wir mehr tun. Eine gemeinsame Aufgabe ist auch, die Altarme wieder anzubinden und dafür zu sorgen, den Flüssen wieder mehr Raum zu geben.\n",
      "\n",
      "Das Problem dabei ist die Zuständigkeitenverteilung zwischen dem Bund und den Ländern. Es gibt unterschiedliche Zuständigkeiten für das Planungsrecht beim Hochwasserschutz auf der einen Seite und bei Renaturierungsmaßnahmen auf der anderen Seite. Einmal sind dies die Wasserwirtschaftsämter, und einmal ist dies die Wasser- und Schifffahrtsverwaltung, die relativ unabhängig voneinander tätig sind.\n",
      "\n",
      "Ich habe vor einem Jahr eine Anfrage an den Bundes- und die Landesminister gerichtet. Man sollte hier zumindest einen Runden Tisch einführen und sich fragen: Was ist unser gemeinsames Ziel? Ist diese ökologische Maßnahme nicht auch für den Hochwasserschutz wichtig? Wäre es deswegen nicht vernünftig, das aus einer Hand zu machen? Hier erwarte ich ein bisschen Entgegenkommen von den Ländern. Ich glaube, wenn das gelänge, dann würden wir auch wieder einen großen Schritt weiter sein.\n",
      "\n",
      "****************************\n",
      "Beispiele von Partei gruene:\n",
      "****************************\n",
      "\n",
      "\n",
      "*******************************\n",
      "Sprecher Brigitte Pothmer:\n",
      "\n",
      "Frau Connemann, Sie haben gerade zum wiederholten Male darauf hingewiesen, dass es die rot-grüne Regierung war, die die Liberalisierung der Zeitarbeit durchgesetzt hat. Haben Sie, wie auch wir, zur Kenntnis genommen, dass das Ziel der Liberalisierung der Zeitarbeit, das darin bestand, Auftragsspitzen abzufedern, nicht erreicht werden konnte und die gesellschaftliche Realität so aussieht - dies wurde in vielen Untersuchungen von verschiedenen Instituten, unter anderem vom Institut für Arbeitsmarkt- und Berufsforschung, nachgewiesen -, dass die Betriebe die Liberalisierung der Leiharbeit stattdessen in erheblichem Umfang genutzt haben, um Stammbelegschaften zu ersetzen? Das war unser Impuls und war unser Ziel nicht.\n",
      "\n",
      "Ich frage Sie: Ist das Ihr Ziel? Wir haben diese Anträge jetzt eingebracht, weil wir feststellen mussten, dass es einen erheblichen Missbrauch gibt, der weit über Schlecker hinausreicht. Ich frage Sie: Sehen Sie diesen Missbrauch nicht? Sind Sie bereit, diesem Missbrauch entgegenzuwirken?\n",
      "\n",
      "*******************************\n",
      "Sprecher Volker Beck:\n",
      "\n",
      "Der Antrag der Fraktion Die Linke wählt einen Ansatz, den wir sehr begrüßen: bei der Menschenrechtspolitik nicht nur mit dem Finger auf ferne Staaten zu zeigen, sondern hier in Deutschland anzufangen. Die Universalität der Menschenrechte zwingt uns dazu, vor unserer Haustür die gleichen Standards anzulegen, die wir von unseren internationalen Partnern weltweit einfordern.\n",
      "\n",
      "Dass in anderen Staaten die Menschenrechte in viel stärkerer Weise als bei uns beeinträchtigt werden, ist uns klar. Mit Schrecken schauen wir auf Folter, Vertreibung, willkürliche Verhaftungen und vieles mehr, vor dem wir uns in Deutschland nicht zu fürchten brauchen. Doch auch in Deutschland gibt es menschenrechtliche Defizite. Sei es die Gewalt gegen Minderheiten, die Diskriminierung wegen der Zugehörigkeit zu einer sozialen Gruppe, zunehmende Armut gerade von Kindern, Barrieren beim Zugang zu Bildung, ungleiche Bezahlung von Frauen und Männern bis hin zum Pflegeskandal im Alter - Verletzungen und Mängel ziehen sich durch viele Bereiche. Menschen anderer Hautfarbe, anderer Religion oder anderer sexueller Orientierung werden auch in der Bundesrepublik Opfer von Hetze und tödlicher Gewalt, genauso wie Obdachlose oder Menschen mit Behinderungen. Und ein ums andere Mal wird die Bundesregierung vom Bundesverfassungsgericht und dem Europäischen Gerichthof getadelt, endlich die verfassungs- und europarechtswidrige Diskriminierung von Schwulen und Lesben zu beenden. Aber anstatt eine vorausschauende und menschenrechtskonforme Antidiskriminierungspolitik zu betreiben, lässt sich Schwarz-Gelb lieber in regelmäßigen Abständen von den Gerichten einen Schlag auf den Hinterkopf verpassen. Was ist eigentlich aus den Gleichstellungsversprechen der Liberalen im Wahlkampf geworden?\n",
      "\n",
      "Wenn wir über den Menschenrechtsschutz in Deutschland sprechen, dürfen wir nicht vergessen, dass zuweilen Menschenrechtsverletzungen gar nicht von staatlichen Akteuren verursacht werden, sondern von transnational agierenden Unternehmen, und dass auch deutsche Unternehmen Menschenrechtsverletzungen begehen. Der weltweite Rohstoffhunger führt dazu, dass Bodenschätze unter menschenrechtswidrigen Bedingungen gefördert und Waren zu unmenschlichen Bedingungen produziert werden. Das Schielen auf Profit führt dazu, dass Unternehmen die von Staaten begangenen Menschenrechtsverletzungen dulden oder zumindest in fahrlässiger Weise fördern. Wir sehen aktuell an der Klage von Opfern der Apartheid unter anderem gegen die Daimler AG, dass auch deutsche Unternehmen bei diesem Spiel beteiligt sein können. Was die Opfer dieser Menschenrechtsverletzungen und Straftaten brauchen, sind keine warmen Worte, sondern rechtliche Möglichkeiten, auch noch nach langer Zeit ihre Schadenersatzansprüche effektiv vor deutschen Gerichten geltend zu machen. Die konservativ-neoliberale Koalition schweigt dazu. Das einzige was ihr einfällt, sind freiwillige Selbstverpflichtungen der Unternehmen, in denen sie sich zur Einhaltung der Menschenrechte im Ausland verpflichten können. Dieses Konzept aber hat sich über die Jahrzehnte hinweg als weitestgehend gescheitert herausgestellt. Um ihren extraterritorialen Staatenpflichten nachzukommen, benötigt die Bundesrepublik endlich Gesetze, die das Verhalten deutscher Unternehmen im Ausland im Umgang mit den Menschenrechten klar regeln. Leider geht auch der Antrag der Fraktion Die Linke hierauf nicht ein. Der vierte periodische Bericht über die Durchführung des Paktes über wirtschaftliche, soziale und kulturelle Rechte der Vereinten Nationen in der Bundesrepublik Deutschland vom 31. August 2001 kritisiert, dass die wirtschaftlichen, sozialen und kulturellen Rechte in Deutschland weniger Beachtung finden und geringer gesichert sind als die bürgerlichen und politischen Rechte. Diese WSK-Rechte werden in Deutschland über das Sozialstaatsgebot geschützt und gewährleistet. Leider begeht auch hier die aktuelle Bundesregierung einen schweren Fehler, indem sie das Fakultativprotokoll zum UN-Sozialpakt nicht ratifiziert. Es wurde über viele Jahre verhandelt. Seine Ratifikation würde für die seit 1973 für Deutschland verbürgten wirtschaftlichen, sozialen und kulturellen Rechte unter anderem eine Individualbeschwerdemöglichkeit etablieren. Deutschland war während der Entstehung des Fakultativprotokolls ein verlässlicher Fürsprecher. Seit 2009 aber prüft die Bundesregierung nun die deutsche Ratifikation des Protokolls. Nachdem zunächst für Ende 2010 ein Kabinettsbeschluss über die Ratifikation angekündigt war, scheint nun der Prozess auf unbestimmte Zeit ausgesetzt zu sein. Hat die Bundesregierung also tatsächlich Angst davor, in Individualbeschwerden auf eigene Missstände hingewiesen zu werden? Ein bisschen mehr Selbstvertrauen wäre hier angebracht: denn ganz so schlimm, wie es der Antrag der Fraktion Die Linke darstellt, ist es um den deutschen Sozialstaat nicht bestellt. Eine Beschwerdeflut wird es also nicht geben.\n",
      "\n",
      "Der Antrag der Fraktion Die Linke geht überdies von einem falschen Verständnis der wirtschaftlichen, sozialen und kulturellen Rechte aus. Die Bundesregierung muss sie respektieren, indem sie die Rechte der Bevölkerung nicht verletzt. Sie muss die Rechte schützen, indem sie dafür sorgt, dass die grundlegenden Rechte nicht durch Dritte verletzt werden, und sie muss diese Rechte erfüllen, indem sie alles in ihrer Macht Stehende unternimmt, um der Bevölkerung diese Rechte zu gewähren. Die WSK-Rechte gewähren jedoch keinen Anspruch auf soziale und wirtschaftliche Gleichheit, wie es sich die Fraktion Die Linke vorstellt. Sie verpflichten die Bundesrepublik vielmehr, gewisse Minimalstandards zu erfüllen und bei der konkreten Umsetzung durch Gesetze, Verordnungen oder politische Maßnahmen keine Diskriminierungen zuzulassen. Die Forderung aus dem Antrag, soziale Grundrechte ausdrücklich in das Grundgesetz aufzunehmen, ist darüber hinaus völlig antipolitisch. Wie möchte die Fraktion Die Linke angesichts einer noch nicht einmal einfachen Mehrheit zur Zweidrittelmehrheit einer Verfassungsänderung gelangen? Zuletzt sei mir noch eines gestattet: Die Menschenrechtspolitik in Deutschland unter die Lupe zu nehmen und stärker einzufordern, ist mir sehr sympathisch. Wenn die Fraktion Die Linke jedoch über die Gegenwart spricht und in die Zukunft blickt, dann sollte sie auch über die Vergangenheit sprechen; denn wie es um das innerstaatliche Menschenrechtsverständnis ihrer Vorgängerpartei aussah, darf in diesem Fall nicht unerwähnt bleiben. Dass die wirtschaftlichen, sozialen und kulturellen Rechte in dem vorliegenden Antrag lautstark eingefordert werden, ist umso bemerkenswerter, als dass die bürgerlichen und politischen Rechte noch vor nicht allzu langer Zeit von einigen jetzt noch in der Partei aktiven Menschen mit Füßen getreten wurden. Wer glaubhafte Menschenrechtspolitik machen möchte, der sollte sich mit seinen eigenen rechtsstaatlichen Verfehlungen zunächst ernsthaft auseinandergesetzt haben. Eine Partei, die ihre politischen Wurzeln auch in einem Unrechtsstaat hat, ist bei Forderungen nach der Einhaltung der Menschenrechte im Innern nur dann glaubwürdig, wenn sie ihre Position aus der Reflexion ihrer eigenen Geschichte heraus gewinnt. Wir Grüne sind der festen Überzeugung, dass sowohl Innen- als auch Außenpolitik an den Menschenrechten ausgerichtet sein müssen; denn nur wer innenpolitisch sich selbst genauso an den menschenrechtlichen Standards misst und messen lässt, wie er außenpolitisch andere danach beurteilt, kann überzeugende Menschenrechtspolitik vertreten.\n",
      "\n",
      "****************************\n",
      "Beispiele von Partei linke:\n",
      "****************************\n",
      "\n",
      "\n",
      "*******************************\n",
      "Sprecher Ulla Jelpke:\n",
      "\n",
      "Ansonsten: Der Gesetzentwurf ist ein ganz gefährlicher Mix aus Gesetzesverschärfung, verfassungswidrigen Leistungseinschränkungen und Abschreckungsmaßnahmen. Das ist genau das Gegenteil dessen, was wir gegenwärtig brauchen. Hier sind häufig genug Solidarität, menschenwürdige Aufnahme und Versorgung der Flüchtlinge eingeklagt worden. Das brauchen wir jetzt. Alle Kraft muss dafür aufgebracht werden. Aber was machen Sie stattdessen in diesem Gesetzentwurf? Flüchtlinge sollen bis zu sechs Monate lang in Erstaufnahmelagern eingezwängt werden, einige sogar so lange, bis sie abgeschoben werden können, und das, obwohl wir wissen, dass dies zusätzliche Konflikte und übrigens auch zusätzliche Kosten verursacht. Wir haben gerade wieder etwas über die Auseinandersetzungen in Flüchtlingslagern gehört.\n",
      "\n",
      "Ich frage Sie hier: Warum versperren Sie sich der Möglichkeit, Schutzsuchende einfach auch zu ihren Familien, Bekannten, Freunden gehen zu lassen? Das betrifft zum Beispiel viele Menschen, die aus Syrien kommen.\n",
      "\n",
      "*******************************\n",
      "Sprecher Jörn Wunderlich:\n",
      "\n",
      "Weiter fordern die Sachverständigen in ihren Handlungsempfehlungen Bund und Länder auf, den Kommunen mehr Mitbestimmung einzuräumen. So empfehlen sie, die Finanzhoheit in diesem Land vom Kopf auf die Füße zu stellen, sowie die Unterstützung von informellen Hilfsnetzwerken aus Familien, Freunden und Nachbarn, die Förderung ehrenamtlichen Engagements älterer Menschen und die verbesserte Beratung für pflegende Angehörige. Dabei muss man aber bei der Förderung des ehrenamtlichen Engagements immer darauf achten, dass sie tatsächlich on top geht, weil das Engagement nicht als Ausfallbürge für angeblich nicht finanzierbare staatliche Aufgaben herhalten darf.\n",
      "\n",
      "So wie die Sachverständigen formuliert auch die Bundesregierung in ihrer Stellungnahme, dass es auf strukturelle, inhaltliche und finanzielle Rahmenbedingungen sowie darauf ankommt, die \"sehr unterschiedlichen Entwicklungen in den Kommunen in Deutschland\" zu beachten. Betroffen seien alle wichtigen Lebensbereiche und die Lebensqualität des Miteinanders aller Generationen vor Ort. Das betrifft Wohnen, Wohnumfeld und Daseinsvorsorge, medizinische, pflegerische und betreuende Versorgung, Selbstbestimmung, Bildung und Information, Mobilität und soziale Kontakte.\n",
      "\n",
      "Eine wichtige Unterscheidung bei der Beschreibung regionaler Vielfalt ist die Differenzierung von städtischem und ländlichem Raum. So gibt es laut Bericht erhebliche Unterschiede hinsichtlich Wohlstand, Infrastruktur und Bevölkerungszusammensetzung. – Alles neue Tatsachen? Da müssen wir uns wirklich an den Kopf fassen: Das war uns doch seit Jahren bekannt. Daraus hätte man schon längst etwas entwickeln müssen.\n",
      "\n",
      "****************************\n",
      "Beispiele von Partei spd:\n",
      "****************************\n",
      "\n",
      "\n",
      "*******************************\n",
      "Sprecher Michael Roth:\n",
      "\n",
      "Parteipolitische Nibelungentreue ist hier völlig fehl am Platze. Wir machen die Entwicklungen schon seit mehreren Jahren zum Thema. Wenn die CDU/CSU schon vor zwei oder drei Jahren in die Allparteienkoalition eingestiegen wäre und sich mit uns gemeinsam dazu entschlossen hätte, gegenüber den politisch Verantwortlichen in Ungarn deutliche Worte zu finden - ob nun vor der Tür oder hinter der Tür; vor allem die Bundeskanzlerin ist da in der Pflicht -, wäre es in Ungarn vielleicht gar nicht so weit gekommen.\n",
      "\n",
      "Wenn Sie immer wieder auf uns zeigen, kann ich ganz selbstbewusst zum Ausdruck bringen: Nicht nur - davon sprach der Kollege Steinmeier - im Hinblick auf die Slowakei haben wir deutliche Worte gefunden, auch im Falle Rumäniens haben wir uns klar geäußert. Die Sozialdemokratische Partei Europas hat ja sogar ihren Parteikongress von Bukarest nach Brüssel verlegt, um öffentlich ein Zeichen zu setzen. Kritik wirkt nur dann, wenn sie öffentlich geäußert wird. Das sollte doch zumindest in der Europäischen Union selbstverständlich sein.\n",
      "\n",
      "Zum Schluss möchte ich sagen: Es geht wirklich nicht nur um Ungarn, und es geht auch nicht nur um unsere eigenen Werte. Es geht auch um die große Frage: Wie tritt die Europäische Union in einer globalisierten Welt gegenüber denjenigen Staaten auf, die tagtäglich Demokratie und Freiheitsrechte mit Füßen treten? Können wir wirklich noch glaubhaft für diese Werte eintreten, wenn wir Zweifel daran lassen, dass wir diese Werte auch innerhalb der Europäischen Union wirklich ernst nehmen? Ich meine hier nicht Sonntagsreden, sondern die tagtägliche politische und gesellschaftliche Arbeit. Deswegen ist diese Diskussion dringend überfällig.\n",
      "\n",
      "*******************************\n",
      "Sprecher Burkhard Blienert:\n",
      "\n",
      "Die Idee einer weitgehenden Legalisierung des Anbaus und Konsums, den ich eher verfolge, setzt auf einen regulierten und kontrollierten Ansatz. Das möchte ich an dieser Stelle gerne betonen.\n",
      "\n",
      "Auch die Akzeptanz des Besitzes in der Größe einer Jahresernte bzw. einer Höchstgrenze von 30 Gramm pro Einkauf sehe ich skeptisch. Über solche Details muss man mit Experten diskutieren und die Grundrichtung eines Gesetzentwurfes nachschärfen. Die Anhörungen der letzten Jahre bestätigen dies auch. Nahezu alle Experten fordern von uns, in Fragen der Drogenpolitik umzudenken. Allein eine Seite des Hauses verweigert sich noch. Die Union verschließt sich nach wie vor den Argumenten. Sie nimmt eine Blockadehaltung ein. Im Koalitionsvertrag ist dazu leider nichts vereinbart worden. Wir hörten in dieser Wahlperiode immer ein striktes Nein. Das ist nicht vorwärtsweisend.\n",
      "\n",
      "Vordergründig geht es um die Grenzen zwischen \"verboten\" und \"erlaubt\", zwischen akzeptiertem Drogenkonsum und Genuss, der nur geduldet wird. Es geht nicht um die Abwägung in der Sache, sondern um die reine Lehre. Was derzeit gilt, wird nicht geändert.\n"
     ]
    }
   ],
   "source": [
    "import os, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "if not os.path.exists(DATADIR): \n",
    "    os.mkdir(DATADIR)\n",
    "\n",
    "file_name = os.path.join(DATADIR, 'bundestags_parlamentsprotokolle.csv.gzip')\n",
    "if not os.path.exists(file_name):\n",
    "    url_data = 'https://www.dropbox.com/s/1nlbfehnrwwa2zj/bundestags_parlamentsprotokolle.csv.gzip?dl=1'\n",
    "    urllib.request.urlretrieve(url_data, file_name)\n",
    "\n",
    "df = pd.read_csv(gzip.open(file_name)).sample(frac=1)\n",
    "\n",
    "alle_sprecher = df.sprecher.unique()\n",
    "parteien = df.partei.unique()\n",
    "partei_farben = {'cducsu':'black', 'linke':'purple', 'spd':'red', 'gruene':'green', 'fdp':'yellow'}\n",
    "\n",
    "print(\"{} Reden wurden geladen\".format(len(df)))\n",
    "\n",
    "# Zeige einige Reden von Parteien\n",
    "for party in np.unique(df['partei']):\n",
    "    print(\"\\n****************************\\nBeispiele von Partei {}:\\n****************************\\n\".format(party))\n",
    "    for _, speech in df[df['partei']==party].sample(2).iterrows():\n",
    "        print(\"\\n*******************************\\nSprecher {}:\\n\\n{}\".format(speech['sprecher'], speech['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "def train(texts, party):\n",
    "    '''\n",
    "    Eine Funktion, die gegeben Texte und Labels einen Klassifier trainiert\n",
    "    '''\n",
    "    stopwords = [w.strip() for w in open(\"data/stopwords.txt\").readlines()]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Eine Machine Learning Pipeline um Bag-of-Words Vectors zu erstellen aus Texten\n",
    "        text_clf = Pipeline([('vect', TfidfVectorizer(stop_words=stopwords)),\n",
    "                            ('clf', SGDClassifier(loss='log', class_weight='balanced'))])\n",
    "        # some hyperparameters\n",
    "        parameters = {\n",
    "            'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "            'vect__max_df': [0.8],\n",
    "            'clf__alpha': (np.logspace(-6, -4, 2)).tolist()\n",
    "        }\n",
    "        # perform gridsearch to get the best regularizer\n",
    "        clf = GridSearchCV(text_clf, parameters, cv=2, n_jobs=-1,verbose=4)\n",
    "        clf.fit(texts, party)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_estimator_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        for params, mean_score, scores in clf.grid_scores_:\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean_score, scores.std() / 2, params))\n",
    "        print()\n",
    "\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainieren eines linearen Klassifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/stopwords.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-df0cdb08957a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Jetzt trainieren wir den Klassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2e3a5ae9679d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(texts, party)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mEine\u001b[0m \u001b[0mFunktion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdie\u001b[0m \u001b[0mgegeben\u001b[0m \u001b[0mTexte\u001b[0m \u001b[0mund\u001b[0m \u001b[0mLabels\u001b[0m \u001b[0meinen\u001b[0m \u001b[0mKlassifier\u001b[0m \u001b[0mtrainiert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     '''\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/stopwords.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/stopwords.txt'"
     ]
    }
   ],
   "source": [
    "# Erst nehmen wir einige Daten beiseite, um das Model darauf spaeter testen zu koennen\n",
    "idx = df.wahlperiode == 18\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['text'][idx], df['partei'][idx], test_size=0.5)\n",
    "\n",
    "# Jetzt trainieren wir den Klassifier\n",
    "clf = train(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorhersage auf Trainings Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     cducsu       0.94      0.57      0.71      8845\n",
      "        fdp       0.00      0.00      0.00         0\n",
      "     gruene       0.50      0.80      0.61      1608\n",
      "      linke       0.67      0.74      0.70      2281\n",
      "        spd       0.56      0.71      0.63      3214\n",
      "\n",
      "avg / total       0.78      0.65      0.68     15948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/Code/Python/ml-schule/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_predictions = clf.predict(train_data)\n",
    "report = classification_report(train_predictions, train_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorhersage auf Test Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     cducsu       0.84      0.60      0.70      3535\n",
      "     gruene       0.31      0.60      0.41       476\n",
      "      linke       0.48      0.60      0.53       692\n",
      "        spd       0.41      0.53      0.47      1308\n",
      "\n",
      "avg / total       0.66      0.58      0.60      6011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = clf.predict(test_data)\n",
    "report = classification_report(test_predictions, test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2113   43   68  302]\n",
      " [ 339  287  143  171]\n",
      " [ 213   96  412  137]\n",
      " [ 870   50   69  698]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download eines Zeitungsartikels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from readability.readability import Document\n",
    "\n",
    "url = \"http://www.spiegel.de/politik/ausland/muss-deutschland-jetzt-milliarden-an-polen-zahlen-a-1167144.html\"\n",
    "html = urllib.request.urlopen(url).read()\n",
    "readable_article = Document(html).summary()\n",
    "readable_title = Document(html).short_title()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifizierung des Zeitungsartikels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeitungsartikel: Muss Deutschland jetzt Milliarden an Polen zahlen?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115ac7588>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKEvSQ0x9CWpIYa+JDXE0Jekhvw/9QMI0gE8ABAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b8acba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = clf.predict_proba([readable_article])\n",
    "\n",
    "print(\"Zeitungsartikel: {}\".format(readable_title))\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.barplot(clf.best_estimator_.steps[1][1].classes_, prediction.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_vectors = clf.steps[0][1].transform(df.text)\n",
    "idx2words = {k:v for v,k in clf.steps[0][1].vocabulary_.items()}\n",
    "for party in np.unique(df['partei']):\n",
    "    this_party = (df['partei'] == party).values * 2 - 1\n",
    "    word_covariance = bow_vectors.T.dot(this_party).argsort()\n",
    "    top_words = [idx2words[widx] for widx in word_covariance[-20:][::-1]]\n",
    "    print(\"*********************\\nPartei {} benutzt haeufig:\\n{}\".format(party, \", \".join(top_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5072100313479624, total=  24.6s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5105982691584097, total=  27.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5311598746081505, total=  56.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5230094043887147, total=  27.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  1.6min remaining:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5212592499686441, total=  54.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5118525021949079, total=  27.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5078369905956113, total=  52.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.4848864919101969, total=  50.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.509 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.526 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.517 (+/-0.003) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.496 (+/-0.006) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     cducsu       0.93      0.55      0.69      3783\n",
      "        fdp       0.00      0.00      0.00         0\n",
      "     gruene       0.46      0.80      0.58       654\n",
      "      linke       0.65      0.70      0.67       977\n",
      "        spd       0.55      0.70      0.62      1421\n",
      "\n",
      "avg / total       0.77      0.63      0.66      6835\n",
      "\n",
      "[[2085    0   17   28  102]\n",
      " [ 499    0   10   19   80]\n",
      " [ 342    0  522  119  150]\n",
      " [ 230    0   44  684   96]\n",
      " [ 627    0   61  127  993]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/Code/Python/ml-schule/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Wir gruppieren nach Sprecher\n",
    "grouped_by_speaker = df.groupby(['sitzung','wahlperiode','sprecher']).agg({'text':lambda x:\" \".join(x), 'partei': lambda x:list(x)[0]})\n",
    "# Erst nehmen wir einige Daten beiseite, um das Model darauf spaeter testen zu koennen\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(grouped_by_speaker['text'], grouped_by_speaker['partei'], test_size=0.3)\n",
    "# Jetzt trainieren wir den Klassifier\n",
    "clf_grouped_by_speaker = train(train_data, train_labels)\n",
    "test_predictions = clf.predict(test_data)\n",
    "report = classification_report(test_predictions, test_labels)\n",
    "print(report)\n",
    "print(confusion_matrix(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x125ad0d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEFCAYAAADuT+DpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f9bc048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['grenzen'] = df.text.str.lower().str.contains('grenzen')\n",
    "df['armut'] = df.text.str.lower().str.contains('armut')\n",
    "df_armut_sicherheit = df.groupby(\"partei\").agg({'grenzen': sum, 'armut':sum})\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "sns.regplot(x='armut', y='grenzen', data=df_armut_sicherheit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tsplot() got multiple values for argument 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-a2c9c90645de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msprecher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Jürgen Trittin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sitzung'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gruene'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'partei'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'gruene'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wahlperiode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sitzung'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gruene'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tsplot() got multiple values for argument 'data'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "sprecher = 'Jürgen Trittin'\n",
    "sns.tsplot('sitzung','gruene',data=df[(df['partei']=='gruene') & (df['wahlperiode']==17)][['sitzung','gruene']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.542488239415474, total=  10.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.551285900130091, total=  10.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5571900330231162, total=  11.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5647953567497248, total=  24.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   38.5s remaining:   38.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.562706435792213, total=  26.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5607046341707537, total=  14.6s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5409786850795557, total=  24.8s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5403863477129417, total=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.547 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.541 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5494197679071628, total=  20.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5426255753452072, total=  21.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5671268507402961, total=  40.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5591236494597839, total=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   57.0s remaining:   57.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5616369821893136, total=  14.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5647388433059836, total=  39.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5363145258103241, total=  19.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5399239543726235, total=  20.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.566 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.560 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.538 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5524580335731415, total=  12.2s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.544727636181909, total=  12.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5583533173461231, total=  13.6s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5637490007993605, total=  28.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.55832083958021, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   40.1s remaining:   40.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5647176411794103, total=  28.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5366316841579211, total=  21.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5428657074340527, total=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.549 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.540 (+/-0.002) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5454272863568216, total=  13.1s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5432370288913326, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5569215392303848, total=  12.2s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5607317804658603, total=  12.1s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5651174412793604, total=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.7s remaining:   39.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5617314805558332, total=  28.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5447365790262921, total=  18.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5399300349825088, total=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.544 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.542 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5461276766059636, total=  12.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5416333066453163, total=  12.8s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.557934760856514, total=  12.5s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5679407644586753, total=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   38.0s remaining:   38.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5595476381104884, total=  12.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5623498799039232, total=  28.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5368294635708567, total=  17.4s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5405243145887533, total=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.544 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.565 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.539 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5506550655065506, total=  13.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5436630989296789, total=  13.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5582558255825583, total=  12.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5662566256625663, total=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.7s remaining:   39.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.56036811043313, total=  12.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5626688006401921, total=  28.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5403540354035403, total=  18.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5344603381014305, total=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.547 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.537 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5510591526778578, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5428285857071464, total=  13.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5583533173461231, total=  13.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5575212393803098, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.4s remaining:   39.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5671462829736211, total=  29.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5617191404297851, total=  28.5s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5390687450039968, total=  18.8s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.536431784107946, total=  19.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.547 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.538 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5495450454954505, total=  12.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5406540654065407, total=  13.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5622437756224378, total=  28.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5578442155784421, total=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.9s remaining:   39.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5634563456345635, total=  28.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5587558755875588, total=  13.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5423457654234577, total=  17.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5431543154315431, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.543 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5500600720865038, total=  13.2s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5404025232802644, total=  13.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5635762915498599, total=  28.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5587705246295555, total=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   41.1s remaining:   41.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.557524782216882, total=  13.9s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5628316811855412, total=  29.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.540548658390068, total=  17.5s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5363973165114649, total=  19.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.538 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5503503503503504, total=  13.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5446535843011614, total=  13.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5594594594594594, total=  12.5s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5622747296756108, total=  12.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.1s remaining:   39.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5683683683683683, total=  28.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5605726872246696, total=  28.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5422422422422423, total=  19.6s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.539146976371646, total=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.548 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.561 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.541 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5489804078368653, total=  12.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5414375687293812, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5580767692922831, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5654738104758097, total=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.7s remaining:   39.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5577326801959412, total=  13.5s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5607317804658603, total=  28.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5391843262694922, total=  18.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5391382585224432, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.539 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5491450854914508, total=  13.1s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5408540854085409, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.557044295570443, total=  12.9s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5589558955895589, total=  12.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5641435856414359, total=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.8s remaining:   39.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5628562856285628, total=  29.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5348534853485348, total=  19.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5389461053894611, total=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.537 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5455998401758066, total=  12.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5408132680587471, total=  13.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.557286984317251, total=  12.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5677754470082909, total=  28.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5606953741632531, total=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.4s remaining:   39.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5652912378859027, total=  27.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5372090700229747, total=  20.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5429113797582176, total=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.543 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.567 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.540 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5467402206619859, total=  12.8s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5416875689776262, total=  13.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5583751253761284, total=  12.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5589445169057891, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.0s remaining:   39.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.567703109327984, total=  28.2s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5635597471656466, total=  28.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5376743252734022, total=  18.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5352056168505517, total=  19.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.544 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.566 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.536 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5482965931863727, total=  12.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5424476295479603, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5549098196392785, total=  11.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5592863586248371, total=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   37.1s remaining:   37.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5673346693386774, total=  26.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5622932745314223, total=  26.2s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5415831663326653, total=  19.4s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5389395609902776, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.565 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.557 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.540 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5448096712958338, total=  11.8s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5404217048066353, total=  12.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5587970826256369, total=  11.8s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5606075746977116, total=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   36.7s remaining:   36.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5662903386951743, total=  26.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5627061057259918, total=  26.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5366170446598062, total=  19.8s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5373238732886979, total=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.543 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.560 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.537 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5493605115907274, total=  11.5s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.543528235882059, total=  12.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5586530775379697, total=  12.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5599200399800099, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   36.8s remaining:   36.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5589205397301349, total=  26.5s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5666466826538769, total=  27.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5356714628297362, total=  17.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5390304847576212, total=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.537 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5483903219356129, total=  12.6s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5428542854285429, total=  12.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5581883623275345, total=  12.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.560956095609561, total=  11.9s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5687862427514497, total=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   37.7s remaining:   37.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5644564456445644, total=  26.8s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5423915216956608, total=  18.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.54005400540054, total=  18.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.567 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.560 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.541 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5453269153630165, total=  11.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5401203610832498, total=  12.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5573606097071802, total=  14.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5673886883273165, total=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   40.2s remaining:   40.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5569709127382146, total=  14.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.560481444332999, total=  28.8s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5413156839149619, total=  21.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5404212637913741, total=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.543 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.557 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.541 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5513140801438993, total=  13.2s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5422746352188687, total=  13.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5580093934246028, total=  14.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5612632420547672, total=  13.9s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5634056160687518, total=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   41.6s remaining:   41.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5569658205076954, total=  29.4s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5395223343659439, total=  21.6s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5363781730961423, total=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.547 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.560 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.560 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.538 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5412412412412413, total=  17.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5435065585260839, total=  17.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5570570570570571, total=  13.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.565065065065065, total=  33.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   45.8s remaining:   45.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5599279062781616, total=  13.1s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5630319415239812, total=  33.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5408408408408408, total=  20.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5416040853109042, total=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.542 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.541 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5518896220755849, total=  12.3s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5403459654034597, total=  12.5s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5639872025594881, total=  27.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5575884823035393, total=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   38.9s remaining:   38.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5621437856214379, total=  12.4s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5596440355964404, total=  28.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5407918416316737, total=  19.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5418458154184581, total=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.003) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.562 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.560 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.541 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5532553255325533, total=  13.6s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5463639091727518, total=  13.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5584558455845584, total=  12.9s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5595678703611083, total=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   40.6s remaining:   40.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5681568156815682, total=  29.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5662698809642893, total=  29.2s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5386538653865387, total=  20.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5393618085425628, total=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.550 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.567 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.539 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5486389111289032, total=  12.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5416416416416416, total=  12.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5575460368294636, total=  12.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5602602602602602, total=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.2s remaining:   39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5654523618895116, total=  28.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5666666666666667, total=  27.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5414331465172137, total=  21.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5428428428428428, total=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.566 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.542 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5509796081567373, total=  12.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5398920215956808, total=  13.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5571771291483406, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5667732906837265, total=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.3s remaining:   39.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5594881023795241, total=  13.0s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5600879824035193, total=  27.9s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5416833266693323, total=  20.6s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5413917216556688, total=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.003) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.542 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5504596322941646, total=  12.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.543074155506696, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5627498001598721, total=  26.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5597521982414069, total=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   37.4s remaining:   37.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5578652808315011, total=  11.9s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5651609034579252, total=  27.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5402677857713829, total=  19.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.536777933240056, total=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.547 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.539 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5489353194041787, total=  12.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5399, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5575327401779466, total=  12.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5639308207537739, total=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.2s remaining:   39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5608, total=  13.0s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5653, total=  27.8s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.537738678396481, total=  20.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5387, total=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.544 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.565 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.538 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5452625226312613, total=  13.5s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.545774647887324, total=  13.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5582377791188896, total=  12.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5629778672032193, total=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   39.7s remaining:   39.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5650774492053913, total=  28.3s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5694164989939637, total=  28.7s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5409456740442656, total=  19.5s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5424461878897606, total=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.567 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.561 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.542 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5441014883628009, total=  12.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5396143470876211, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5552891818999101, total=  12.1s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.567975227250025, total=  27.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   38.5s remaining:   38.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5602957338395445, total=  12.0s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5645918673194126, total=  27.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5397063230446509, total=  19.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5380157857927865, total=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.542 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.566 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.539 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5525, total=  12.5s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.54250850170034, total=  12.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5593, total=  13.2s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.566, total=  27.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5589117823564713, total=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   40.0s remaining:   40.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5626125225045009, total=  28.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5331, total=  19.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5417083416683337, total=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.548 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.564 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.537 (+/-0.002) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5471716969818109, total=  12.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.544036788963311, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5574655206875875, total=  12.3s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5604318704388683, total=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   38.5s remaining:   38.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5663601838896662, total=  28.0s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.56333100069979, total=  27.5s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5445732560463722, total=  18.6s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5442367289813056, total=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.565 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.544 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5448910217956409, total=  11.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5445, total=  11.9s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5571885622875425, total=  11.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5704859028194361, total=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   36.9s remaining:   36.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.559, total=  11.9s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5596, total=  26.1s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5407918416316737, total=  17.5s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5377, total=  18.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.545 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.565 (+/-0.003) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.558 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.539 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5483903219356129, total=  12.7s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5442, total=  12.6s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5581883623275345, total=  12.2s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5657868426314737, total=  27.0s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5616, total=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   38.1s remaining:   38.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5639, total=  26.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.543, total=  17.2s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5415916816636672, total=  19.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.565 (+/-0.000) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.560 (+/-0.001) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.542 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5475784618469869, total=  12.5s\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5442326980942829, total=  12.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1) ...\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5589090544470069, total=  11.9s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 1), score=0.5586760280842528, total=  11.7s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   37.9s remaining:   37.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5663290885390555, total=  27.4s\n",
      "[CV] clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2) ...\n",
      "[CV]  clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5602808425275827, total=  27.2s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5369107321965898, total=  19.1s\n",
      "[CV]  clf__alpha=0.0001, vect__max_df=0.8, vect__ngram_range=(1, 2), score=0.5360473277850195, total=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "  ...='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))])\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.546 (+/-0.001) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.563 (+/-0.002) for {'clf__alpha': 1e-06, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "0.559 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 1)}\n",
      "0.536 (+/-0.000) for {'clf__alpha': 0.0001, 'vect__max_df': 0.8, 'vect__ngram_range': (1, 2)}\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 1) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n",
      "[CV] clf__alpha=1e-06, vect__max_df=0.8, vect__ngram_range=(1, 2) ....\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "for sprecher in alle_sprecher:\n",
    "\n",
    "    traindf = df[(df['sprecher']!=sprecher) & (df['wahlperiode']==18)]\n",
    "    testdf = df[(df['sprecher']==sprecher) & (df['wahlperiode']==18)].sort_values(['sitzung'])\n",
    "    \n",
    "    if (len(traindf) > 10) and (len(testdf) > 10):\n",
    "\n",
    "        tmpclf = train(traindf.text, traindf.partei)\n",
    "        predictions = tmpclf.predict_proba(testdf.text)\n",
    "        cla()\n",
    "        for partei_idx in range(predictions.shape[-1]):\n",
    "            partei = clf.classes_[partei_idx]\n",
    "            color = partei_farben[partei]\n",
    "            plot(testdf.sitzung, predictions[:, partei_idx],\"o\",color=color)\n",
    "            title(\"{} - ({})\".format(sprecher,partei))\n",
    "            savefig(sprecher + \".pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
